{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["![Py4Eng](img/logo.png)\n", "\n", "# Reinforcement learning\n", "## Yoav Ram"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Reinforcement learning is a semi-supervied learning method in which we don't have target _per se_, but can still evaluate the value of model predictions, even if only after the fact.\n", "\n", "In many exmaples of reinforcement learning the model is trained to play a game.\n", "In this spirit, we'll train a model to play the simplest thinking game of all: tic-tac-toe, or X-O.\n", "This is similar to [teaching a pigeon to play checkers](https://www.youtube.com/watch?v=TYY3A06cgaY).\n", "\n", "![X-O](https://duckduckgo.com/i/60ac44b2.png)\n", "\n", "But there are many much more sophisticated examples and uses for RL, for example (click on the images to follow the links):\n", "\n", "[![pong](http://karpathy.github.io/assets/rl/pong.gif)](http://karpathy.github.io/2016/05/31/rl/)\n", "\n", "[![catch](https://edersantana.github.io/articles/keras_rl/catch.gif)](https://edersantana.github.io/articles/keras_rl/)\n", "\n", "[![jumping](https://www.cs.ubc.ca/~van/papers/2016-TOG-deepRL/dog_teaser.png)](https://www.cs.ubc.ca/~van/papers/2016-TOG-deepRL/index.html)\n", "\n", "[![AlphaGo](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/FloorGoban.JPG/300px-FloorGoban.JPG)](https://deepmind.com/research/alphago/)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%matplotlib inline\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "import itertools\n", "import time\n", "import pickle\n", "from collections import defaultdict\n", "from IPython.display import HTML\n", "import tensorflow as tf\n", "try:\n", "    import keras\n", "except ModuleNotFoundError:\n", "    from tensorflow import keras\n", "print('GPU:', tf.test.is_gpu_available())\n", "import seaborn as sns\n", "sns.set(\n", "    style='ticks',\n", "    context='talk',\n", "    palette='Set1'\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Basic game elements\n", "\n", "We will model a board as an array of 18 elements. \n", "The first 9 are for player x and the last 9 are for player o.\n", "Each 9 elements represent a 3x3 board for that player, with ones where the player put her mark (x or o) and zeros where she didn't.\n", "\n", "The first function is for displaying a board."]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"data": {"text/html": ["<table><tr><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td></tr><tr><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'>x</td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'>o</td></tr><tr><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'>x</td></tr></table>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["int_to_str = {0: ' ', 1: 'x', 2: 'o'}\n", "css = \"\"\"\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "\"\"\"\n", "def display(board):\n", "    board = (board[:9] + 2 * board[9:]).reshape((3, 3))\n", "    table = \"<table>\"\n", "    for i in range(3):\n", "        table += \"<tr>\"\n", "        for j in range(3):\n", "            table += \"<td style='{}'>{}</td>\".format(css, int_to_str[board[i,j]])\n", "        table += \"</tr>\"\n", "    table += \"</table>\"\n", "    return HTML(table.format(*board.ravel()))\n", "    \n", "board = np.zeros(18)\n", "board[4] = 1\n", "board[9 + 5] = 1\n", "board[8] = 1\n", "display(board)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The next function checks if a move is legal, i.e., is not trying to put a mark where an x or o mark is already there."]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["def is_legal_move(board, move):\n", "    return 0 <= move < 9 and board[move] == 0 and board[9 + move] == 0"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["False False\n"]}, {"data": {"text/html": ["<table><tr><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'>x</td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td></tr><tr><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td></tr><tr><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td></tr></table>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["board = np.zeros(18)\n", "board[0] = 1\n", "print(is_legal_move(board, 0), is_legal_move(board, -1))\n", "display(board)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now a function that draws a **random legal move**."]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["def random_move(board):\n", "    board = board[:9] + board[9:]\n", "    board = board.reshape((3, 3))\n", "    empty = np.where(board.ravel() == 0)[0]\n", "    return np.random.choice(empty, 1)[0]"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"data": {"text/html": ["<table><tr><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'>x</td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td></tr><tr><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'>x</td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td></tr><tr><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'> </td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'>o</td></tr></table>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": ["board = np.zeros(18)\n", "board[random_move(board)] = 1\n", "board[9 + random_move(board)] = 1\n", "board[random_move(board)] = 1\n", "display(board)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The next functions check if the board is full or if a specific player has won."]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["def is_full(board):\n", "    return (board[:9] + board[9:]).all()\n", "\n", "def is_winner(board, player):\n", "    board = board[9:] if player else board[:9]\n", "    board = board.reshape((3, 3))\n", "    if (board[0,:].all() or \n", "        board[1,:].all() or \n", "        board[2,:].all() or \n", "        board[:,0].all() or \n", "        board[:,1].all() or \n", "        board[:,2].all()):\n", "        return True\n", "    elif board[0,0] and board[1,1] and board[2,2]:\n", "        return True\n", "    elif board[0,2] and board[1,1] and board[2,0]:\n", "        return True\n", "    return False"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"data": {"text/html": ["<table><tr><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'>o</td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'>o</td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'>x</td></tr><tr><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'>x</td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'>x</td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'>o</td></tr><tr><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'>x</td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'>x</td><td style='\n", "    width:2em;\n", "    height:2em;\n", "    border: 1px solid #000; \n", "    background: white;\n", "    text-align: center;\n", "    \n", "'>o</td></tr></table>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["board = np.zeros(18)\n", "player = 1\n", "while not is_winner(board, player) and not is_full(board):\n", "    player = (player + 1) % 2\n", "    move = random_move(board)\n", "    board[9*player + move] = 1    \n", "display(board)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Model\n", "\n", "We use Keras to build a simple model with one dense layer and a softmax readout layer.\n", "\n", "The model input is the current board as an array of 18 elements; the model output is a probability vector for the 9 possible moves (0-8)."]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["model = keras.models.Sequential()\n", "model.add(keras.layers.Dense(128, input_shape=(18,), activation='relu'))\n", "model.add(keras.layers.Dense(9))\n", "model.add(keras.layers.Activation('softmax'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We use the **mean squared error** as a loss function and a simple stochastic gradient descent optimizer. The choice of mean squared error will become clear when we see how the targets ($y$) are constructed."]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["model.compile(keras.optimizers.SGD(lr=.2), \"mse\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Playing a game\n", "\n", "The model will be player x, and player o will be implemented with naive random moves.\n", "\n", "If the model wins, it gets a reward of 1. If it losses the reward is -1. Ties give a reward of 0.\n", "This rewards will be used to construct the targets ($y$) so that when the model chose a move that lead to a win/loss/tie we will reinforce that move using a reward of 1/-1/0 using the mean squared error loss function.\n", "\n", "Note that at the begining, the random player 2 has an advantage because it never plays an illegal move, so at least it knows the rules.\n", "The model (player 1), on the other hand, plays illegal moves and will be penalized for them: he losses (reward is -1) when it plays an illegal move. This will allow our model to learn the rules.\n", "\n", "During a game, sometimes (with probability $\\epsilon$) we let the model choose a random move instead of the move it would choose using it's prediction function. This is done to add some noise and help get the model out of bad strategies. This strategy is called _exploration_.\n", "\n", "During the game we save at each step the prediction and the move that the model chose, and in the last step we also save the reward. \n", "That game \"memory\" is the result of the `play_game` function."]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": ["def play_game(verbose=False, \u03f5= 0.1):\n", "    board = np.zeros(18, dtype=int)\n", "    memory = []\n", "\n", "    for i in range(5): # max number of turns is 5\n", "        turn = dict()\n", "        memory.append(turn)\n", "        \n", "        turn['board'] = board.copy()\n", "\n", "        if is_full(board):\n", "            if verbose: print('board full')\n", "            turn['reward'] = 0\n", "            break\n", "            \n", "        # player x\n", "        if np.random.rand() < \u03f5: # exploration\n", "            pred = np.ones(9) / 9\n", "        else: # exploitation\n", "            # predicts expects 2D and returns 2D\n", "            pred = model.predict(board.reshape(1,-1)).ravel() \n", "        move = np.random.multinomial(1, pred).argmax() # draw random move from move distribution\n", "        turn['pred'] = pred\n", "        turn['move'] = move\n", "\n", "        if not is_legal_move(board, move):\n", "            if verbose: print('illegal move by player x:', move)\n", "            turn['reward'] = -1\n", "            break\n", "\n", "        board[move] = 1\n", "        \n", "        if is_winner(board, 0): \n", "            if verbose: print('player x wins')\n", "            turn['reward'] = 1\n", "            break\n", "            \n", "        # player o\n", "        if is_full(board):\n", "            if verbose: print('board full')\n", "            turn['reward'] = 0\n", "            break\n", "            \n", "        move = random_move(board)\n", "        board[9 + move] = 1\n", "        \n", "        if is_winner(board, 1): \n", "            if verbose: print('player o wins')\n", "            turn['reward'] = -1\n", "            break\n", "    return memory"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Training"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Before training the model player x is pretty bad, getting a negative average score and winning only 7%-9% of games."]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["X won 9.10% and lost 90.80% of games\n"]}], "source": ["def score(num_games=1000):\n", "    scores = np.array([play_game(\u03f5=0)[-1]['reward'] for _ in range(num_games)])\n", "    return (scores==1).mean(), (scores==0).mean(), (scores==-1).mean()\n", "\n", "wins, ties, losses = score(1000)\n", "print(\"X won {:.2%} and lost {:.2%} of games\".format(wins, losses))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Training on a single game is done by stacking the game boards (one for every x turn) as inputs ($X$).\n", "\n", "The targets ($Y$) is an array of zeros with the reward at the index of the move the model chose.\n", "\n", "So the model should try to increase the probability of choosing moves with reward of 1 (wins) and decrease the probability of choosing moves with reward -1."]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["def train_on_game(memory):\n", "    X = [] # boards\n", "    Y = [] # rewards\n", "    reward = memory[-1]['reward']\n", "    \n", "    for turn in memory:\n", "        board = turn['board']\n", "        X.append(board)\n", "        \n", "        y = np.zeros(9)\n", "        move = turn['move']\n", "        y[move] = reward\n", "        Y.append(y)\n", "\n", "    X = np.array(X)\n", "    Y = np.array(Y)\n", "    return model.train_on_batch(X, Y)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's train the model."]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": ["def train(num_of_games):\n", "    # we define \"epoch\" so that we have 10 epochs overall\n", "    epoch = num_of_games//10 \n", "    loss = 0\n", "    tic = time.time()\n", "    for i in range(1, num_of_games + 1):\n", "        memory = play_game()\n", "        loss += train_on_game(memory) # sum losses since epoch started\n", "        if i % epoch == 0:\n", "            toc = time.time()\n", "            # print elapsed time and average epoch loss\n", "            print(\"{} games: {:.4f} seconds, loss={:.4f}\".format(i, toc-tic, loss/epoch))\n", "            tic = toc\n", "            loss = 0"]}, {"cell_type": "code", "execution_count": 43, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["10000 games: 17.1543 seconds, loss=0.1431\n", "20000 games: 17.2152 seconds, loss=0.1410\n", "30000 games: 18.1610 seconds, loss=0.1399\n", "40000 games: 17.8315 seconds, loss=0.1393\n", "50000 games: 18.7205 seconds, loss=0.1385\n", "60000 games: 20.0695 seconds, loss=0.1375\n", "70000 games: 19.1501 seconds, loss=0.1364\n", "80000 games: 19.2436 seconds, loss=0.1346\n", "90000 games: 19.6842 seconds, loss=0.1332\n", "100000 games: 17.8237 seconds, loss=0.1309\n"]}], "source": ["train(100000)"]}, {"cell_type": "code", "execution_count": 44, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["X won 32.30% and lost 67.20% of games\n"]}], "source": ["wins, ties, losses = score(1000)\n", "print(\"X won {:.2%} and lost {:.2%} of games\".format(wins, losses))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["After training on 100,000 games the model still has a negative score, but wins ~32% of games rather than ~7%.\n", "\n", "Lets keep training; note that one epoch is a tenth of the training time, so the duration per epoch will be higher now."]}, {"cell_type": "code", "execution_count": 45, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["40000 games: 74.1880 seconds, loss=0.1241\n", "80000 games: 78.1307 seconds, loss=0.1134\n", "120000 games: 79.7379 seconds, loss=0.1091\n", "160000 games: 77.0359 seconds, loss=0.1071\n", "200000 games: 75.8316 seconds, loss=0.1059\n", "240000 games: 70.6603 seconds, loss=0.1059\n", "280000 games: 73.6886 seconds, loss=0.1047\n", "320000 games: 72.2727 seconds, loss=0.1051\n", "360000 games: 72.4834 seconds, loss=0.1048\n", "400000 games: 71.6227 seconds, loss=0.1046\n"]}], "source": ["train(400000)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["After 500,000 games, its already at ~66% winning."]}, {"cell_type": "code", "execution_count": 47, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["X won 65.60% and lost 34.30% of games\n"]}], "source": ["wins, ties, losses = score(1000)\n", "print(\"X won {:.2%} and lost {:.2%} of games\".format(wins, losses))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Colophon\n", "This notebook was written by [Yoav Ram](http://python.yoavram.com).\n", "\n", "The notebook was written using [Python](http://python.org/) 3.7.\n", "\n", "This work is licensed under a [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/) International License.\n", "\n", "![Python logo](https://www.python.org/static/community_logos/python-logo.png)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.6"}}, "nbformat": 4, "nbformat_minor": 4}