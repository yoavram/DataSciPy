{"cells": [{"cell_type": "code", "execution_count": null, "id": "98a78a42", "metadata": {}, "outputs": [], "source": ["## Python version\n", "def _cross_entropy(X, Y, a):\n", "    nsamples = Y.shape[0] \n", "    Z = logodds(X, a)\n", "    return -sum(\n", "        -z*(1-y) - np.log(1+np.exp(-z)) \n", "        for z, y \n", "        in zip(Z, Y)\n", "    ) / nsamples"]}, {"cell_type": "code", "execution_count": null, "id": "cef4c68e", "metadata": {}, "outputs": [], "source": ["## NumPy version\n", "def cross_entropy(X, Y, a):\n", "    Z = logodds(X, a)\n", "    logliks = -Z * (1 - Y) - np.log(1 + np.exp(-Z))\n", "    return -logliks.mean()"]}, {"cell_type": "code", "execution_count": null, "id": "fe82bffe", "metadata": {}, "outputs": [], "source": ["def gradient_descent(X, Y, a, \u03b7=0.01):\n", "    nsamples = Y.shape[0]\n", "    \n", "    Z = X @ a\n", "    Yhat = 1 / (1 + np.exp(-Z))\n", "    \u03b4 = Yhat - Y\n", "    dJda = X.T @ \u03b4 / nsamples\n", "    assert dJda.shape == a.shape\n", "    return a - \u03b7 * dJda"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.2"}}, "nbformat": 4, "nbformat_minor": 5}