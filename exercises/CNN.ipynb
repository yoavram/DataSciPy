{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN: Fashion-MNIST \n",
    "\n",
    "This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images. This dataset can be used as a drop-in replacement for MNIST. The class labels are:\n",
    "\n",
    "\n",
    "| Label |\tDescription|\n",
    "|---|------------------|\n",
    "| 0 |\tT-shirt/top    |\n",
    "| 1 |\tTrouser        |\n",
    "| 2 |\tPullover       |\n",
    "| 3 |\tDress          |\n",
    "| 4 |\tCoat           |\n",
    "| 5 |\tSandal         |\n",
    "| 6 |\tShirt          |\n",
    "| 7 |\tSneaker        |\n",
    "| 8 |\tBag            |\n",
    "| 9 |\tAnkle boot     |\n",
    "\n",
    "See [keras docs](https://keras.io/datasets/).\n",
    "\n",
    "In this exercise we will train a CNN on the dataset.\n",
    "You can use either TensorFlow or Keras.\n",
    "The [solution](../solutions/CNN.ipynb) is in the `solutions` folder.\n",
    "\n",
    "We'll get the data via [`keras.datasets`](https://keras.io/datasets/).\n",
    "It takes some time to download, and you should also install keras (`conda install keras`) rather than use the keras supplied with TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 22:35:42.125778: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow: 2.13.1\n",
      "Keras: 2.13.1\n",
      "GPU: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print('Tensorflow:', tf.__version__)    \n",
    "print('Keras:', keras.__version__)\n",
    "print('GPU:', tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert the images to a float32 between 0 and 1 and reshape to 28x28x1 (only one channel for black and white) because 2D convolutions expect 3D images (3rd dimension is channel or image).\n",
    "\n",
    "We also need to one-hot encode the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "x_test = x_test.reshape((-1, 28, 28, 1))\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"125.28pt\" height=\"125.28pt\" viewBox=\"0 0 125.28 125.28\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-11-01T12:50:11.483871</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 125.28 \n",
       "L 125.28 125.28 \n",
       "L 125.28 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 7.2 118.08 \n",
       "L 118.08 118.08 \n",
       "L 118.08 7.2 \n",
       "L 7.2 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p918a90364e)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image92d4a4a55b\" transform=\"scale(1 -1) translate(0 -110.88)\" x=\"7.2\" y=\"-7.2\" width=\"110.88\" height=\"110.88\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\"/>\n",
       "   <g id=\"matplotlib.axis_2\"/>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 7.2 118.08 \n",
       "L 7.2 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 118.08 118.08 \n",
       "L 118.08 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 7.2 118.08 \n",
       "L 118.08 118.08 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 7.2 7.2 \n",
       "L 118.08 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p918a90364e\">\n",
       "   <rect x=\"7.2\" y=\"7.2\" width=\"110.88\" height=\"110.88\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 174,
       "width": 174
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(0, x_train.shape[0])\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(x_train[i, :, :, 0], cmap='gray_r')\n",
    "plt.xticks([]); plt.yticks([])\n",
    "print(y_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build and train the CNN.\n",
    "When I trained a CNN I got this accuracy of ~87% on the test set, see if you can top it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('../data/keras_cnn_fashion_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DataSciPy]",
   "language": "python",
   "name": "conda-env-DataSciPy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
