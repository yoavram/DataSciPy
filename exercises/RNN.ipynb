{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with Keras\n",
    "\n",
    "In practice, there are some [problems with training RNN](https://towardsdatascience.com/understanding-lstm-and-its-quick-implementation-in-keras-for-sentiment-analysis-af410fd85b47), and most applications use a variation called [LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "\n",
    "Let's use an LSTM network to [predict word completions](http://curiousily.com/data-science/2017/05/23/tensorflow-for-hackers-part-5.html) for [Jonathan Swift](https://en.wikipedia.org/wiki/Jonathan_Swift), the author of Gulliver's Travels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "try:\n",
    "    import keras\n",
    "except ModuleNotFoundError:\n",
    "    from tensorflow import keras\n",
    "print('GPU:', tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is at `../data/Gulliver.txt` and contains the Project Gutenberg's version of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters: 308221\n",
      "Number of unique characters: 85\n",
      "Number of lines: 5586\n",
      "Number of words: 51438\n",
      "\n",
      "Excerpt:\n",
      "********\n",
      "Title: Gulliver's Travels\n",
      "       Into Several Remote Regions of the World\n",
      "\n",
      "\n",
      "Author: Jonathan Swift\n",
      "\n",
      "Editor: Thomas M. Balliet\n",
      "\n",
      "Release Date: November 26, 2005  [eBook #17157]\n",
      "\n",
      "Language: English\n",
      "\n",
      "Character set encoding: ISO-646-US (US-ASCII)\n",
      "\n",
      "\n",
      "***START OF THE PROJECT GUTENBERG EBOOK GULLIVER'S TRAVEL\n"
     ]
    }
   ],
   "source": [
    "filename = '../data/Gulliver.txt'\n",
    "text = open(filename, 'rt').read()\n",
    "text = text[352:]\n",
    "print(\"Number of characters: {}\".format(len(text)))\n",
    "print(\"Number of unique characters: {}\".format(len(set(text))))\n",
    "print(\"Number of lines: {}\".format(text.count('\\n')))\n",
    "print(\"Number of words: {}\".format(text.count(' ')))\n",
    "print()\n",
    "print(\"Excerpt:\")\n",
    "print(\"*\" * len(\"Excerpt:\"))\n",
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create mappings from characters to integers and from integers to characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(set(text))\n",
    "data_size, vocab_size = len(text), len(chars)\n",
    "\n",
    "id_to_char = dict(enumerate(chars)) # { i: ch for i,ch in enumerate(chars) }\n",
    "char_to_id = dict(zip(id_to_char.values(), id_to_char.keys())) # { ch: i for i,ch in enumerate(chars) }\n",
    "data = np.array([char_to_id[c] for c in text], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use sequences of length 40 and with a step size of 3 so that we don't have complete overlap.\n",
    "\n",
    "The following generates `X` and `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sequences: 102727\n",
      "Title: Gulliver's Travels\n",
      "       Into Se -> v\n"
     ]
    }
   ],
   "source": [
    "seq_length = 40\n",
    "step = 3\n",
    "sequences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - seq_length, step):\n",
    "    sequences.append(text[i: i + seq_length])\n",
    "    next_chars.append(text[i + seq_length])\n",
    "n_sequences = len(sequences)\n",
    "print('# sequences:', n_sequences)\n",
    "print(sequences[0], '->', next_chars[0])\n",
    "\n",
    "X = np.zeros((n_sequences, seq_length, vocab_size), dtype=np.bool)\n",
    "Y = np.zeros((n_sequences, vocab_size), dtype=np.bool)\n",
    "\n",
    "for i, seq in enumerate(sequences):\n",
    "    for t, char in enumerate(seq):\n",
    "        X[i, t, char_to_id[char]] = 1\n",
    "    Y[i, char_to_id[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the model using Keras**.\n",
    "Use one or more LSTM layers and consider what is the correct output layer.\n",
    "Note that the input to an LSTM layer is a sequence, so if you connect two LSTM layers you need the earlier one to return a sequence -- there's a special argument for that in the LSTM constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, None, 128)         109568    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 32)                20608     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 85)                2805      \n",
      "=================================================================\n",
      "Total params: 132,981\n",
      "Trainable params: 132,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    # your code here\n",
    "]\n",
    "model = keras.models.Sequential(layers)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    # your code here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure accuracy on a test set, we tell Keras to split of the data for a train and test set.\n",
    "\n",
    "Other training parameters are the batch size - number of samples or sequences per gradient update - and epochs - number of times we want to iterate over the entire data.\n",
    "\n",
    "**Choose the training parameters and run the training**. This may take about 30-60 secons per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = ###\n",
    "batch_size = ###\n",
    "epochs = ###\n",
    "\n",
    "history = model.fit(\n",
    "    X, Y, \n",
    "    validation_split=test_size, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot the change in accuracy and loss over the training time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['acc'], label='train')\n",
    "plt.plot(history['val_acc'], label='test')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply the model for text completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(sentence):\n",
    "    # one-hot encode\n",
    "    x = np.zeros((1, len(sentence), vocab_size), dtype=float)\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[0, t, char_to_id[char]] = 1\n",
    "        \n",
    "    completion = ''\n",
    "    while True:\n",
    "        # predict char distribution\n",
    "        pred = model.predict(x).squeeze() # returns 2D array\n",
    "        # sample char\n",
    "        char_id = np.random.multinomial(1, pred).argmax()\n",
    "        next_char = id_to_char[char_id]\n",
    "        completion += next_char\n",
    "        if completion in (' ', '\\n', '.', ',', ';'): # can't have a completion of a single non-char\n",
    "            completion = ''\n",
    "            continue\n",
    "        if next_char in (' ', '\\n'): # if next char is space/newline, stop completion\n",
    "            break        \n",
    "        # update x\n",
    "        new_x = np.zeros((1, 1, vocab_size))\n",
    "        new_x[0, 0, char_id] = 1\n",
    "        x = np.concatenate((x, new_x), axis=1)\n",
    "        \n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Good morning, sir, how are yo'\n",
    "print(sentence, '...', complete(sentence), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Good morning, sir, how is every'\n",
    "print(sentence, '...', complete(sentence), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Good evening, sir, how is every'\n",
    "print(sentence, '...', complete(sentence), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colophon\n",
    "This notebook was written by [Yoav Ram](http://python.yoavram.com) and is part of the [_Data Science with Python_](https://github.com/yoavram/DataSciPy) workshop.\n",
    "\n",
    "The notebook was written using [Python](http://python.org/) 3.6.5.\n",
    "\n",
    "This work is licensed under a [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/) International License.\n",
    "\n",
    "![Python logo](https://www.python.org/static/community_logos/python-logo.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
